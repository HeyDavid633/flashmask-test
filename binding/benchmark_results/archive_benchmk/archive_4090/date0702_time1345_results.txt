=== Testing batch_size: 1 ===
bs:1 | h_num:12 | seq:128
 PyTorch version: 2.6.0a0+df5bbc09d1.nv24.12
 CUDA version 	: 12.6
 GPU cuda:(0) 	: NVIDIA GeForce RTX 4090 
 --------------------------------------------------
 bs:1 | seq:128 |  Torch Naive : 0.314 ms / iter
 bs:1 | seq:128 |  FlashAttn2  : 0.071 ms / iter
 bs:1 | seq:128 |   FlexAttn   : 0.107 ms / iter
 bs:1 | seq:128 |  Bind Kernel : 0.062 ms / iter |  Speedup/FA2: 1.142
 
bs:1 | h_num:12 | seq:256
 PyTorch version: 2.6.0a0+df5bbc09d1.nv24.12
 CUDA version 	: 12.6
 GPU cuda:(0) 	: NVIDIA GeForce RTX 4090 
 --------------------------------------------------
 bs:1 | seq:256 |  Torch Naive : 0.307 ms / iter
 bs:1 | seq:256 |  FlashAttn2  : 0.068 ms / iter
 bs:1 | seq:256 |   FlexAttn   : 0.105 ms / iter
 bs:1 | seq:256 |  Bind Kernel : 0.060 ms / iter |  Speedup/FA2: 1.122
 
bs:1 | h_num:12 | seq:512
 PyTorch version: 2.6.0a0+df5bbc09d1.nv24.12
 CUDA version 	: 12.6
 GPU cuda:(0) 	: NVIDIA GeForce RTX 4090 
 --------------------------------------------------
 bs:1 | seq:512 |  Torch Naive : 0.310 ms / iter
 bs:1 | seq:512 |  FlashAttn2  : 0.079 ms / iter
 bs:1 | seq:512 |   FlexAttn   : 0.129 ms / iter
 bs:1 | seq:512 |  Bind Kernel : 0.088 ms / iter |  Speedup/FA2: 0.902
 
bs:1 | h_num:12 | seq:1024
 PyTorch version: 2.6.0a0+df5bbc09d1.nv24.12
 CUDA version 	: 12.6
 GPU cuda:(0) 	: NVIDIA GeForce RTX 4090 
 --------------------------------------------------
 bs:1 | seq:1024 |  Torch Naive : 0.312 ms / iter
 bs:1 | seq:1024 |  FlashAttn2  : 0.081 ms / iter
 bs:1 | seq:1024 |   FlexAttn   : 0.112 ms / iter
 bs:1 | seq:1024 |  Bind Kernel : 0.070 ms / iter |  Speedup/FA2: 1.149
 
bs:1 | h_num:12 | seq:2048
 PyTorch version: 2.6.0a0+df5bbc09d1.nv24.12
 CUDA version 	: 12.6
 GPU cuda:(0) 	: NVIDIA GeForce RTX 4090 
 --------------------------------------------------
 bs:1 | seq:2048 |  Torch Naive : 1.236 ms / iter
 bs:1 | seq:2048 |  FlashAttn2  : 0.114 ms / iter
 bs:1 | seq:2048 |   FlexAttn   : 0.131 ms / iter
 bs:1 | seq:2048 |  Bind Kernel : 0.121 ms / iter |  Speedup/FA2: 0.937
 
bs:1 | h_num:12 | seq:4096
 PyTorch version: 2.6.0a0+df5bbc09d1.nv24.12
 CUDA version 	: 12.6
 GPU cuda:(0) 	: NVIDIA GeForce RTX 4090 
 --------------------------------------------------
 bs:1 | seq:4096 |  Torch Naive : 5.059 ms / iter
 bs:1 | seq:4096 |  FlashAttn2  : 0.251 ms / iter
 bs:1 | seq:4096 |   FlexAttn   : 0.289 ms / iter
 bs:1 | seq:4096 |  Bind Kernel : 0.270 ms / iter |  Speedup/FA2: 0.929
 
=== Testing batch_size: 8 ===
bs:8 | h_num:12 | seq:128
 PyTorch version: 2.6.0a0+df5bbc09d1.nv24.12
 CUDA version 	: 12.6
 GPU cuda:(0) 	: NVIDIA GeForce RTX 4090 
 --------------------------------------------------
 bs:8 | seq:128 |  Torch Naive : 0.368 ms / iter
 bs:8 | seq:128 |  FlashAttn2  : 0.069 ms / iter
 bs:8 | seq:128 |   FlexAttn   : 0.103 ms / iter
 bs:8 | seq:128 |  Bind Kernel : 0.060 ms / iter |  Speedup/FA2: 1.161
 
bs:8 | h_num:12 | seq:256
 PyTorch version: 2.6.0a0+df5bbc09d1.nv24.12
 CUDA version 	: 12.6
 GPU cuda:(0) 	: NVIDIA GeForce RTX 4090 
 --------------------------------------------------
 bs:8 | seq:256 |  Torch Naive : 0.361 ms / iter
 bs:8 | seq:256 |  FlashAttn2  : 0.066 ms / iter
 bs:8 | seq:256 |   FlexAttn   : 0.100 ms / iter
 bs:8 | seq:256 |  Bind Kernel : 0.059 ms / iter |  Speedup/FA2: 1.120
 
bs:8 | h_num:12 | seq:512
 PyTorch version: 2.6.0a0+df5bbc09d1.nv24.12
 CUDA version 	: 12.6
 GPU cuda:(0) 	: NVIDIA GeForce RTX 4090 
 --------------------------------------------------
 bs:8 | seq:512 |  Torch Naive : 0.482 ms / iter
 bs:8 | seq:512 |  FlashAttn2  : 0.069 ms / iter
 bs:8 | seq:512 |   FlexAttn   : 0.107 ms / iter
 bs:8 | seq:512 |  Bind Kernel : 0.062 ms / iter |  Speedup/FA2: 1.113
 
bs:8 | h_num:12 | seq:1024
 PyTorch version: 2.6.0a0+df5bbc09d1.nv24.12
 CUDA version 	: 12.6
 GPU cuda:(0) 	: NVIDIA GeForce RTX 4090 
 --------------------------------------------------
 bs:8 | seq:1024 |  Torch Naive : 2.136 ms / iter
 bs:8 | seq:1024 |  FlashAttn2  : 0.123 ms / iter
 bs:8 | seq:1024 |   FlexAttn   : 0.136 ms / iter
 bs:8 | seq:1024 |  Bind Kernel : 0.132 ms / iter |  Speedup/FA2: 0.927
 
bs:8 | h_num:12 | seq:2048
 PyTorch version: 2.6.0a0+df5bbc09d1.nv24.12
 CUDA version 	: 12.6
 GPU cuda:(0) 	: NVIDIA GeForce RTX 4090 
 --------------------------------------------------
 bs:8 | seq:2048 |  Torch Naive : 11.237 ms / iter
 bs:8 | seq:2048 |  FlashAttn2  : 0.408 ms / iter
 bs:8 | seq:2048 |   FlexAttn   : 0.447 ms / iter
 bs:8 | seq:2048 |  Bind Kernel : 0.437 ms / iter |  Speedup/FA2: 0.934
 
bs:8 | h_num:12 | seq:4096
 PyTorch version: 2.6.0a0+df5bbc09d1.nv24.12
 CUDA version 	: 12.6
 GPU cuda:(0) 	: NVIDIA GeForce RTX 4090 
 --------------------------------------------------
 bs:8 | seq:4096 |  Torch Naive : 39.198 ms / iter
 bs:8 | seq:4096 |  FlashAttn2  : 1.443 ms / iter
 bs:8 | seq:4096 |   FlexAttn   : 1.559 ms / iter
 bs:8 | seq:4096 |  Bind Kernel : 1.482 ms / iter |  Speedup/FA2: 0.973
 
=== Testing batch_size: 16 ===
bs:16 | h_num:12 | seq:128
 PyTorch version: 2.6.0a0+df5bbc09d1.nv24.12
 CUDA version 	: 12.6
 GPU cuda:(0) 	: NVIDIA GeForce RTX 4090 
 --------------------------------------------------
 bs:16 | seq:128 |  Torch Naive : 0.376 ms / iter
 bs:16 | seq:128 |  FlashAttn2  : 0.068 ms / iter
 bs:16 | seq:128 |   FlexAttn   : 0.108 ms / iter
 bs:16 | seq:128 |  Bind Kernel : 0.062 ms / iter |  Speedup/FA2: 1.100
 
bs:16 | h_num:12 | seq:256
 PyTorch version: 2.6.0a0+df5bbc09d1.nv24.12
 CUDA version 	: 12.6
 GPU cuda:(0) 	: NVIDIA GeForce RTX 4090 
 --------------------------------------------------
 bs:16 | seq:256 |  Torch Naive : 0.364 ms / iter
 bs:16 | seq:256 |  FlashAttn2  : 0.067 ms / iter
 bs:16 | seq:256 |   FlexAttn   : 0.111 ms / iter
 bs:16 | seq:256 |  Bind Kernel : 0.063 ms / iter |  Speedup/FA2: 1.059
 
bs:16 | h_num:12 | seq:512
 PyTorch version: 2.6.0a0+df5bbc09d1.nv24.12
 CUDA version 	: 12.6
 GPU cuda:(0) 	: NVIDIA GeForce RTX 4090 
 --------------------------------------------------
 bs:16 | seq:512 |  Torch Naive : 1.141 ms / iter
 bs:16 | seq:512 |  FlashAttn2  : 0.070 ms / iter
 bs:16 | seq:512 |   FlexAttn   : 0.129 ms / iter
 bs:16 | seq:512 |  Bind Kernel : 0.080 ms / iter |  Speedup/FA2: 0.873
 
bs:16 | h_num:12 | seq:1024
 PyTorch version: 2.6.0a0+df5bbc09d1.nv24.12
 CUDA version 	: 12.6
 GPU cuda:(0) 	: NVIDIA GeForce RTX 4090 
 --------------------------------------------------
 bs:16 | seq:1024 |  Torch Naive : 4.237 ms / iter
 bs:16 | seq:1024 |  FlashAttn2  : 0.225 ms / iter
 bs:16 | seq:1024 |   FlexAttn   : 0.248 ms / iter
 bs:16 | seq:1024 |  Bind Kernel : 0.242 ms / iter |  Speedup/FA2: 0.929
 
bs:16 | h_num:12 | seq:2048
 PyTorch version: 2.6.0a0+df5bbc09d1.nv24.12
 CUDA version 	: 12.6
 GPU cuda:(0) 	: NVIDIA GeForce RTX 4090 
 --------------------------------------------------
 bs:16 | seq:2048 |  Torch Naive : 22.357 ms / iter
 bs:16 | seq:2048 |  FlashAttn2  : 0.753 ms / iter
 bs:16 | seq:2048 |   FlexAttn   : 0.820 ms / iter
 bs:16 | seq:2048 |  Bind Kernel : 0.801 ms / iter |  Speedup/FA2: 0.940
 
bs:16 | h_num:12 | seq:4096
 PyTorch version: 2.6.0a0+df5bbc09d1.nv24.12
 CUDA version 	: 12.6
 GPU cuda:(0) 	: NVIDIA GeForce RTX 4090 
 --------------------------------------------------
 bs:16 | seq:4096 |  Torch Naive : 78.154 ms / iter
 bs:16 | seq:4096 |  FlashAttn2  : 2.776 ms / iter
 bs:16 | seq:4096 |   FlexAttn   : 2.956 ms / iter
 bs:16 | seq:4096 |  Bind Kernel : 2.810 ms / iter |  Speedup/FA2: 0.988
 

Benchmark end at: Wed Jul  2 13:49:40 UTC 2025
Total test duration: 224 seconds
