=== Testing batch_size: 1 ===
bs:1 | h_num:12 | seq:128
 PyTorch version: 2.6.0a0+df5bbc09d1.nv24.12
 CUDA version 	: 12.6
 GPU cuda:(0) 	: NVIDIA GeForce RTX 4090 
 --------------------------------------------------
 bs:1 | seq:128 |  Torch Naive : 0.314 ms / iter
 bs:1 | seq:128 |  FlashAttn2  : 0.088 ms / iter
 bs:1 | seq:128 |   FlexAttn   : 0.120 ms / iter
 bs:1 | seq:128 |  Bind Kernel : 0.066 ms / iter |  Speedup/FA2: 1.329
 
bs:1 | h_num:12 | seq:256
 PyTorch version: 2.6.0a0+df5bbc09d1.nv24.12
 CUDA version 	: 12.6
 GPU cuda:(0) 	: NVIDIA GeForce RTX 4090 
 --------------------------------------------------
 bs:1 | seq:256 |  Torch Naive : 0.321 ms / iter
 bs:1 | seq:256 |  FlashAttn2  : 0.085 ms / iter
 bs:1 | seq:256 |   FlexAttn   : 0.121 ms / iter
 bs:1 | seq:256 |  Bind Kernel : 0.065 ms / iter |  Speedup/FA2: 1.309
 
bs:1 | h_num:12 | seq:512
 PyTorch version: 2.6.0a0+df5bbc09d1.nv24.12
 CUDA version 	: 12.6
 GPU cuda:(0) 	: NVIDIA GeForce RTX 4090 
 --------------------------------------------------
 bs:1 | seq:512 |  Torch Naive : 0.311 ms / iter
 bs:1 | seq:512 |  FlashAttn2  : 0.092 ms / iter
 bs:1 | seq:512 |   FlexAttn   : 0.122 ms / iter
 bs:1 | seq:512 |  Bind Kernel : 0.067 ms / iter |  Speedup/FA2: 1.366
 
bs:1 | h_num:12 | seq:1024
 PyTorch version: 2.6.0a0+df5bbc09d1.nv24.12
 CUDA version 	: 12.6
 GPU cuda:(0) 	: NVIDIA GeForce RTX 4090 
 --------------------------------------------------
 bs:1 | seq:1024 |  Torch Naive : 0.301 ms / iter
 bs:1 | seq:1024 |  FlashAttn2  : 0.092 ms / iter
 bs:1 | seq:1024 |   FlexAttn   : 0.120 ms / iter
 bs:1 | seq:1024 |  Bind Kernel : 0.069 ms / iter |  Speedup/FA2: 1.337
 
bs:1 | h_num:12 | seq:2048
 PyTorch version: 2.6.0a0+df5bbc09d1.nv24.12
 CUDA version 	: 12.6
 GPU cuda:(0) 	: NVIDIA GeForce RTX 4090 
 --------------------------------------------------
 bs:1 | seq:2048 |  Torch Naive : 1.234 ms / iter
 bs:1 | seq:2048 |  FlashAttn2  : 0.114 ms / iter
 bs:1 | seq:2048 |   FlexAttn   : 0.123 ms / iter
 bs:1 | seq:2048 |  Bind Kernel : 0.121 ms / iter |  Speedup/FA2: 0.939
 
bs:1 | h_num:12 | seq:4096
 PyTorch version: 2.6.0a0+df5bbc09d1.nv24.12
 CUDA version 	: 12.6
 GPU cuda:(0) 	: NVIDIA GeForce RTX 4090 
 --------------------------------------------------
 bs:1 | seq:4096 |  Torch Naive : 5.050 ms / iter
 bs:1 | seq:4096 |  FlashAttn2  : 0.251 ms / iter
 bs:1 | seq:4096 |   FlexAttn   : 0.290 ms / iter
 bs:1 | seq:4096 |  Bind Kernel : 0.270 ms / iter |  Speedup/FA2: 0.929
 
=== Testing batch_size: 8 ===
bs:8 | h_num:12 | seq:128
 PyTorch version: 2.6.0a0+df5bbc09d1.nv24.12
 CUDA version 	: 12.6
 GPU cuda:(0) 	: NVIDIA GeForce RTX 4090 
 --------------------------------------------------
 bs:8 | seq:128 |  Torch Naive : 0.374 ms / iter
 bs:8 | seq:128 |  FlashAttn2  : 0.080 ms / iter
 bs:8 | seq:128 |   FlexAttn   : 0.115 ms / iter
 bs:8 | seq:128 |  Bind Kernel : 0.062 ms / iter |  Speedup/FA2: 1.290
 
bs:8 | h_num:12 | seq:256
 PyTorch version: 2.6.0a0+df5bbc09d1.nv24.12
 CUDA version 	: 12.6
 GPU cuda:(0) 	: NVIDIA GeForce RTX 4090 
 --------------------------------------------------
 bs:8 | seq:256 |  Torch Naive : 0.378 ms / iter
 bs:8 | seq:256 |  FlashAttn2  : 0.079 ms / iter
 bs:8 | seq:256 |   FlexAttn   : 0.119 ms / iter
 bs:8 | seq:256 |  Bind Kernel : 0.060 ms / iter |  Speedup/FA2: 1.324
 
bs:8 | h_num:12 | seq:512
 PyTorch version: 2.6.0a0+df5bbc09d1.nv24.12
 CUDA version 	: 12.6
 GPU cuda:(0) 	: NVIDIA GeForce RTX 4090 
 --------------------------------------------------
 bs:8 | seq:512 |  Torch Naive : 0.479 ms / iter
 bs:8 | seq:512 |  FlashAttn2  : 0.084 ms / iter
 bs:8 | seq:512 |   FlexAttn   : 0.120 ms / iter
 bs:8 | seq:512 |  Bind Kernel : 0.062 ms / iter |  Speedup/FA2: 1.344
 
bs:8 | h_num:12 | seq:1024
 PyTorch version: 2.6.0a0+df5bbc09d1.nv24.12
 CUDA version 	: 12.6
 GPU cuda:(0) 	: NVIDIA GeForce RTX 4090 
 --------------------------------------------------
 bs:8 | seq:1024 |  Torch Naive : 2.136 ms / iter
 bs:8 | seq:1024 |  FlashAttn2  : 0.123 ms / iter
 bs:8 | seq:1024 |   FlexAttn   : 0.136 ms / iter
 bs:8 | seq:1024 |  Bind Kernel : 0.133 ms / iter |  Speedup/FA2: 0.929
 
bs:8 | h_num:12 | seq:2048
 PyTorch version: 2.6.0a0+df5bbc09d1.nv24.12
 CUDA version 	: 12.6
 GPU cuda:(0) 	: NVIDIA GeForce RTX 4090 
 --------------------------------------------------
 bs:8 | seq:2048 |  Torch Naive : 11.237 ms / iter
 bs:8 | seq:2048 |  FlashAttn2  : 0.408 ms / iter
 bs:8 | seq:2048 |   FlexAttn   : 0.446 ms / iter
 bs:8 | seq:2048 |  Bind Kernel : 0.437 ms / iter |  Speedup/FA2: 0.934
 
bs:8 | h_num:12 | seq:4096
 PyTorch version: 2.6.0a0+df5bbc09d1.nv24.12
 CUDA version 	: 12.6
 GPU cuda:(0) 	: NVIDIA GeForce RTX 4090 
 --------------------------------------------------
 bs:8 | seq:4096 |  Torch Naive : 39.192 ms / iter
 bs:8 | seq:4096 |  FlashAttn2  : 1.442 ms / iter
 bs:8 | seq:4096 |   FlexAttn   : 1.548 ms / iter
 bs:8 | seq:4096 |  Bind Kernel : 1.463 ms / iter |  Speedup/FA2: 0.985
 
=== Testing batch_size: 16 ===
bs:16 | h_num:12 | seq:128
 PyTorch version: 2.6.0a0+df5bbc09d1.nv24.12
 CUDA version 	: 12.6
 GPU cuda:(0) 	: NVIDIA GeForce RTX 4090 
 --------------------------------------------------
 bs:16 | seq:128 |  Torch Naive : 0.385 ms / iter
 bs:16 | seq:128 |  FlashAttn2  : 0.085 ms / iter
 bs:16 | seq:128 |   FlexAttn   : 0.120 ms / iter
 bs:16 | seq:128 |  Bind Kernel : 0.064 ms / iter |  Speedup/FA2: 1.328
 
bs:16 | h_num:12 | seq:256
 PyTorch version: 2.6.0a0+df5bbc09d1.nv24.12
 CUDA version 	: 12.6
 GPU cuda:(0) 	: NVIDIA GeForce RTX 4090 
 --------------------------------------------------
 bs:16 | seq:256 |  Torch Naive : 0.384 ms / iter
 bs:16 | seq:256 |  FlashAttn2  : 0.089 ms / iter
 bs:16 | seq:256 |   FlexAttn   : 0.122 ms / iter
 bs:16 | seq:256 |  Bind Kernel : 0.064 ms / iter |  Speedup/FA2: 1.389
 
bs:16 | h_num:12 | seq:512
 PyTorch version: 2.6.0a0+df5bbc09d1.nv24.12
 CUDA version 	: 12.6
 GPU cuda:(0) 	: NVIDIA GeForce RTX 4090 
 --------------------------------------------------
 bs:16 | seq:512 |  Torch Naive : 1.139 ms / iter
 bs:16 | seq:512 |  FlashAttn2  : 0.105 ms / iter
 bs:16 | seq:512 |   FlexAttn   : 0.118 ms / iter
 bs:16 | seq:512 |  Bind Kernel : 0.076 ms / iter |  Speedup/FA2: 1.371
 
bs:16 | h_num:12 | seq:1024
 PyTorch version: 2.6.0a0+df5bbc09d1.nv24.12
 CUDA version 	: 12.6
 GPU cuda:(0) 	: NVIDIA GeForce RTX 4090 
 --------------------------------------------------
 bs:16 | seq:1024 |  Torch Naive : 4.238 ms / iter
 bs:16 | seq:1024 |  FlashAttn2  : 0.225 ms / iter
 bs:16 | seq:1024 |   FlexAttn   : 0.248 ms / iter
 bs:16 | seq:1024 |  Bind Kernel : 0.242 ms / iter |  Speedup/FA2: 0.927
 
bs:16 | h_num:12 | seq:2048
 PyTorch version: 2.6.0a0+df5bbc09d1.nv24.12
 CUDA version 	: 12.6
 GPU cuda:(0) 	: NVIDIA GeForce RTX 4090 
 --------------------------------------------------
 bs:16 | seq:2048 |  Torch Naive : 22.357 ms / iter
 bs:16 | seq:2048 |  FlashAttn2  : 0.753 ms / iter
 bs:16 | seq:2048 |   FlexAttn   : 0.820 ms / iter
 bs:16 | seq:2048 |  Bind Kernel : 0.775 ms / iter |  Speedup/FA2: 0.972
 
bs:16 | h_num:12 | seq:4096
 PyTorch version: 2.6.0a0+df5bbc09d1.nv24.12
 CUDA version 	: 12.6
 GPU cuda:(0) 	: NVIDIA GeForce RTX 4090 
 --------------------------------------------------
 bs:16 | seq:4096 |  Torch Naive : 78.144 ms / iter
 bs:16 | seq:4096 |  FlashAttn2  : 2.782 ms / iter
 bs:16 | seq:4096 |   FlexAttn   : 2.964 ms / iter
 bs:16 | seq:4096 |  Bind Kernel : 2.818 ms / iter |  Speedup/FA2: 0.987
 

Benchmark end at: Thu Jul  3 13:57:35 UTC 2025
Total test duration: 199 seconds
