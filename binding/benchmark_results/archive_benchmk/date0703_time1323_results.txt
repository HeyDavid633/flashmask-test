=== Testing batch_size: 1 ===
bs:1 | h_num:12 | seq:128
 PyTorch version: 2.6.0a0+df5bbc09d1.nv24.12
 CUDA version 	: 12.6
 GPU cuda:(0) 	: NVIDIA GeForce RTX 4090 
 --------------------------------------------------
 bs:1 | seq:128 |  Torch Naive : 0.300 ms / iter
 bs:1 | seq:128 |  FlashAttn2  : 0.067 ms / iter
 bs:1 | seq:128 |   FlexAttn   : 0.102 ms / iter
 bs:1 | seq:128 |  Bind Kernel : 0.062 ms / iter |  Speedup/FA2: 1.082
 
bs:1 | h_num:12 | seq:256
 PyTorch version: 2.6.0a0+df5bbc09d1.nv24.12
 CUDA version 	: 12.6
 GPU cuda:(0) 	: NVIDIA GeForce RTX 4090 
 --------------------------------------------------
 bs:1 | seq:256 |  Torch Naive : 0.317 ms / iter
 bs:1 | seq:256 |  FlashAttn2  : 0.069 ms / iter
 bs:1 | seq:256 |   FlexAttn   : 0.104 ms / iter
 bs:1 | seq:256 |  Bind Kernel : 0.093 ms / iter |  Speedup/FA2: 0.743
 
bs:1 | h_num:12 | seq:512
 PyTorch version: 2.6.0a0+df5bbc09d1.nv24.12
 CUDA version 	: 12.6
 GPU cuda:(0) 	: NVIDIA GeForce RTX 4090 
 --------------------------------------------------
 bs:1 | seq:512 |  Torch Naive : 0.302 ms / iter
 bs:1 | seq:512 |  FlashAttn2  : 0.074 ms / iter
 bs:1 | seq:512 |   FlexAttn   : 0.103 ms / iter
 bs:1 | seq:512 |  Bind Kernel : 0.066 ms / iter |  Speedup/FA2: 1.114
 
bs:1 | h_num:12 | seq:1024
 PyTorch version: 2.6.0a0+df5bbc09d1.nv24.12
 CUDA version 	: 12.6
 GPU cuda:(0) 	: NVIDIA GeForce RTX 4090 
 --------------------------------------------------
 bs:1 | seq:1024 |  Torch Naive : 0.300 ms / iter
 bs:1 | seq:1024 |  FlashAttn2  : 0.076 ms / iter
 bs:1 | seq:1024 |   FlexAttn   : 0.106 ms / iter
 bs:1 | seq:1024 |  Bind Kernel : 0.068 ms / iter |  Speedup/FA2: 1.128
 
bs:1 | h_num:12 | seq:2048
 PyTorch version: 2.6.0a0+df5bbc09d1.nv24.12
 CUDA version 	: 12.6
 GPU cuda:(0) 	: NVIDIA GeForce RTX 4090 
 --------------------------------------------------
 bs:1 | seq:2048 |  Torch Naive : 1.241 ms / iter
 bs:1 | seq:2048 |  FlashAttn2  : 0.117 ms / iter
 bs:1 | seq:2048 |   FlexAttn   : 0.123 ms / iter
 bs:1 | seq:2048 |  Bind Kernel : 0.121 ms / iter |  Speedup/FA2: 0.963
 
bs:1 | h_num:12 | seq:4096
 PyTorch version: 2.6.0a0+df5bbc09d1.nv24.12
 CUDA version 	: 12.6
 GPU cuda:(0) 	: NVIDIA GeForce RTX 4090 
 --------------------------------------------------
 bs:1 | seq:4096 |  Torch Naive : 5.041 ms / iter
 bs:1 | seq:4096 |  FlashAttn2  : 0.253 ms / iter
 bs:1 | seq:4096 |   FlexAttn   : 0.287 ms / iter
 bs:1 | seq:4096 |  Bind Kernel : 0.266 ms / iter |  Speedup/FA2: 0.951
 
=== Testing batch_size: 8 ===
bs:8 | h_num:12 | seq:128
 PyTorch version: 2.6.0a0+df5bbc09d1.nv24.12
 CUDA version 	: 12.6
 GPU cuda:(0) 	: NVIDIA GeForce RTX 4090 
 --------------------------------------------------
 bs:8 | seq:128 |  Torch Naive : 0.366 ms / iter
 bs:8 | seq:128 |  FlashAttn2  : 0.068 ms / iter
 bs:8 | seq:128 |   FlexAttn   : 0.101 ms / iter
 bs:8 | seq:128 |  Bind Kernel : 0.060 ms / iter |  Speedup/FA2: 1.128
 
bs:8 | h_num:12 | seq:256
 PyTorch version: 2.6.0a0+df5bbc09d1.nv24.12
 CUDA version 	: 12.6
 GPU cuda:(0) 	: NVIDIA GeForce RTX 4090 
 --------------------------------------------------
 bs:8 | seq:256 |  Torch Naive : 0.386 ms / iter
 bs:8 | seq:256 |  FlashAttn2  : 0.071 ms / iter
 bs:8 | seq:256 |   FlexAttn   : 0.103 ms / iter
 bs:8 | seq:256 |  Bind Kernel : 0.061 ms / iter |  Speedup/FA2: 1.170
 
bs:8 | h_num:12 | seq:512
 PyTorch version: 2.6.0a0+df5bbc09d1.nv24.12
 CUDA version 	: 12.6
 GPU cuda:(0) 	: NVIDIA GeForce RTX 4090 
 --------------------------------------------------
 bs:8 | seq:512 |  Torch Naive : 0.479 ms / iter
 bs:8 | seq:512 |  FlashAttn2  : 0.072 ms / iter
 bs:8 | seq:512 |   FlexAttn   : 0.126 ms / iter
 bs:8 | seq:512 |  Bind Kernel : 0.081 ms / iter |  Speedup/FA2: 0.892
 
bs:8 | h_num:12 | seq:1024
 PyTorch version: 2.6.0a0+df5bbc09d1.nv24.12
 CUDA version 	: 12.6
 GPU cuda:(0) 	: NVIDIA GeForce RTX 4090 
 --------------------------------------------------
 bs:8 | seq:1024 |  Torch Naive : 2.137 ms / iter
 bs:8 | seq:1024 |  FlashAttn2  : 0.123 ms / iter
 bs:8 | seq:1024 |   FlexAttn   : 0.162 ms / iter
 bs:8 | seq:1024 |  Bind Kernel : 0.133 ms / iter |  Speedup/FA2: 0.923
 
bs:8 | h_num:12 | seq:2048
 PyTorch version: 2.6.0a0+df5bbc09d1.nv24.12
 CUDA version 	: 12.6
 GPU cuda:(0) 	: NVIDIA GeForce RTX 4090 
 --------------------------------------------------
 bs:8 | seq:2048 |  Torch Naive : 11.243 ms / iter
 bs:8 | seq:2048 |  FlashAttn2  : 0.407 ms / iter
 bs:8 | seq:2048 |   FlexAttn   : 0.447 ms / iter
 bs:8 | seq:2048 |  Bind Kernel : 0.437 ms / iter |  Speedup/FA2: 0.932
 
bs:8 | h_num:12 | seq:4096
 PyTorch version: 2.6.0a0+df5bbc09d1.nv24.12
 CUDA version 	: 12.6
 GPU cuda:(0) 	: NVIDIA GeForce RTX 4090 
 --------------------------------------------------
 bs:8 | seq:4096 |  Torch Naive : 39.191 ms / iter
 bs:8 | seq:4096 |  FlashAttn2  : 1.442 ms / iter
 bs:8 | seq:4096 |   FlexAttn   : 1.558 ms / iter
 bs:8 | seq:4096 |  Bind Kernel : 1.483 ms / iter |  Speedup/FA2: 0.972
 
=== Testing batch_size: 16 ===
bs:16 | h_num:12 | seq:128
 PyTorch version: 2.6.0a0+df5bbc09d1.nv24.12
 CUDA version 	: 12.6
 GPU cuda:(0) 	: NVIDIA GeForce RTX 4090 
 --------------------------------------------------
 bs:16 | seq:128 |  Torch Naive : 0.368 ms / iter
 bs:16 | seq:128 |  FlashAttn2  : 0.069 ms / iter
 bs:16 | seq:128 |   FlexAttn   : 0.123 ms / iter
 bs:16 | seq:128 |  Bind Kernel : 0.081 ms / iter |  Speedup/FA2: 0.856
 
bs:16 | h_num:12 | seq:256
 PyTorch version: 2.6.0a0+df5bbc09d1.nv24.12
 CUDA version 	: 12.6
 GPU cuda:(0) 	: NVIDIA GeForce RTX 4090 
 --------------------------------------------------
 bs:16 | seq:256 |  Torch Naive : 0.371 ms / iter
 bs:16 | seq:256 |  FlashAttn2  : 0.068 ms / iter
 bs:16 | seq:256 |   FlexAttn   : 0.102 ms / iter
 bs:16 | seq:256 |  Bind Kernel : 0.062 ms / iter |  Speedup/FA2: 1.100
 
bs:16 | h_num:12 | seq:512
 PyTorch version: 2.6.0a0+df5bbc09d1.nv24.12
 CUDA version 	: 12.6
 GPU cuda:(0) 	: NVIDIA GeForce RTX 4090 
 --------------------------------------------------
 bs:16 | seq:512 |  Torch Naive : 1.141 ms / iter
 bs:16 | seq:512 |  FlashAttn2  : 0.070 ms / iter
 bs:16 | seq:512 |   FlexAttn   : 0.124 ms / iter
 bs:16 | seq:512 |  Bind Kernel : 0.078 ms / iter |  Speedup/FA2: 0.888
 
bs:16 | h_num:12 | seq:1024
 PyTorch version: 2.6.0a0+df5bbc09d1.nv24.12
 CUDA version 	: 12.6
 GPU cuda:(0) 	: NVIDIA GeForce RTX 4090 
 --------------------------------------------------
 bs:16 | seq:1024 |  Torch Naive : 4.236 ms / iter
 bs:16 | seq:1024 |  FlashAttn2  : 0.224 ms / iter
 bs:16 | seq:1024 |   FlexAttn   : 0.249 ms / iter
 bs:16 | seq:1024 |  Bind Kernel : 0.242 ms / iter |  Speedup/FA2: 0.927
 
bs:16 | h_num:12 | seq:2048
 PyTorch version: 2.6.0a0+df5bbc09d1.nv24.12
 CUDA version 	: 12.6
 GPU cuda:(0) 	: NVIDIA GeForce RTX 4090 
 --------------------------------------------------
 bs:16 | seq:2048 |  Torch Naive : 22.356 ms / iter
 bs:16 | seq:2048 |  FlashAttn2  : 0.753 ms / iter
 bs:16 | seq:2048 |   FlexAttn   : 0.819 ms / iter
 bs:16 | seq:2048 |  Bind Kernel : 0.797 ms / iter |  Speedup/FA2: 0.945
 
bs:16 | h_num:12 | seq:4096
 PyTorch version: 2.6.0a0+df5bbc09d1.nv24.12
 CUDA version 	: 12.6
 GPU cuda:(0) 	: NVIDIA GeForce RTX 4090 
 --------------------------------------------------
 bs:16 | seq:4096 |  Torch Naive : 78.148 ms / iter
 bs:16 | seq:4096 |  FlashAttn2  : 2.781 ms / iter
 bs:16 | seq:4096 |   FlexAttn   : 2.900 ms / iter
 bs:16 | seq:4096 |  Bind Kernel : 2.823 ms / iter |  Speedup/FA2: 0.985
 

Benchmark end at: Thu Jul  3 13:26:41 UTC 2025
Total test duration: 199 seconds
